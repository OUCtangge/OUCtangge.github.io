{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OUCtangge/OUCtangge.github.io/blob/main/swirl_dynamics/projects/probabilistic_diffusion/colabs/demo2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIW-If53CiPL"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czOvyn7HCbgV"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/google-research/swirl-dynamics.git@main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2DJBuEdCpFc"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP6GQNwnCrwz"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDKhSAGaCrk2"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "\n",
        "from clu import metric_writers\n",
        "import jax\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import optax\n",
        "import orbax.checkpoint as ocp\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from swirl_dynamics import templates\n",
        "from swirl_dynamics.lib import diffusion as dfn_lib\n",
        "from swirl_dynamics.lib import solvers as solver_lib\n",
        "from swirl_dynamics.projects import probabilistic_diffusion as dfn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ylBqVdcCvcz"
      },
      "source": [
        "## Example I - Unconditional diffusion model with guidance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVzRTpB5Dgm2"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THwrp-2UD2iS"
      },
      "source": [
        "First we need a dataset containing samples whose distribution is to be modeled by the diffusion model. For demonstration purpose, we use the MNIST dataset provided by TensorFlow Datasets.\n",
        "\n",
        "Our code setup accepts any Python iterable objects to be used as dataloaders. The expectation is that they should continuously yield a dictionary with a field named `x` whose corresponding value is a numpy array with shape `(batch, *spatial_dims, channels)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRf3AcadCvKj"
      },
      "outputs": [],
      "source": [
        "def get_mnist_dataset(split: str, batch_size: int):\n",
        "  ds = tfds.load(\"mnist\", split=split)\n",
        "  ds = ds.map(\n",
        "      # Change field name from \"image\" to \"x\" (required by `DenoisingModel`)\n",
        "      # and normalize the value to [0, 1].\n",
        "      lambda x: {\"x\": tf.cast(x[\"image\"], tf.float32) / 255.0}\n",
        "  )\n",
        "  ds = ds.repeat()\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "  ds = ds.as_numpy_iterator()\n",
        "  return ds\n",
        "\n",
        "# The standard deviation of the normalized dataset.\n",
        "# This is useful for determining the diffusion scheme and preconditioning\n",
        "# of the neural network parametrization.\n",
        "DATA_STD = 0.31"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5tZdk5eEQhh"
      },
      "source": [
        "### Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA4hHUeHEVoE"
      },
      "source": [
        "Next let's define the U-Net backbone. The \"Preconditioning\" is to ensure that the inputs and outputs of the network are roughly standardized (for more details, see Appendix B.6. in [this paper](https://arxiv.org/abs/2206.00364))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HE1-wf7aETEH"
      },
      "outputs": [],
      "source": [
        "denoiser_model = dfn_lib.PreconditionedDenoiserUNet(\n",
        "    out_channels=1,\n",
        "    num_channels=(64, 128),\n",
        "    downsample_ratio=(2, 2),\n",
        "    num_blocks=4,\n",
        "    noise_embed_dim=128,\n",
        "    padding=\"SAME\",\n",
        "    use_attention=True,\n",
        "    use_position_encoding=True,\n",
        "    num_heads=8,\n",
        "    sigma_data=DATA_STD,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Htjx7TxAEsKW"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5i7oh2WFFU0"
      },
      "source": [
        "For diffusion model training, the above-defined U-Net backbone serves as a denoiser, which takes as input a batch of (isotropic Gaussian noise) corrupted samples and outputs its best guess for what the uncorrupted image would be.\n",
        "\n",
        "Besides the backbone architecture, we also need to specify how to sample the noise levels (i.e. standard deviations) used to corrupt the samples and the weighting for each noise level in the loss function (for available options and configurations, see [`swirl_dynamics.lib.diffusion.diffusion`](https://github.com/google-research/swirl-dynamics/blob/main/swirl_dynamics/lib/diffusion/diffusion.py)):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l52TFsPEEp5u"
      },
      "outputs": [],
      "source": [
        "diffusion_scheme = dfn_lib.Diffusion.create_variance_exploding(\n",
        "    sigma=dfn_lib.tangent_noise_schedule(),\n",
        "    data_std=DATA_STD,\n",
        ")\n",
        "\n",
        "model = dfn.DenoisingModel(\n",
        "    # `input_shape` must agree with the expected sample shape (without the batch\n",
        "    # dimension), which in this case is simply the dimensions of a single MNIST\n",
        "    # sample.\n",
        "    input_shape=(28, 28, 1),\n",
        "    denoiser=denoiser_model,\n",
        "    noise_sampling=dfn_lib.log_uniform_sampling(\n",
        "        diffusion_scheme, clip_min=1e-4, uniform_grid=True,\n",
        "    ),\n",
        "    noise_weighting=dfn_lib.edm_weighting(data_std=DATA_STD),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76a8RhUpFLoe"
      },
      "source": [
        "We are now ready to define the learning parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8fl_R1gEp36"
      },
      "outputs": [],
      "source": [
        "# !rm -R -f $workdir  # optional: clear the working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4DAOL_xEp1k"
      },
      "outputs": [],
      "source": [
        "num_train_steps = 100_000  #@param\n",
        "workdir = \"/tmp/diffusion_demo_mnist\"  #@param\n",
        "train_batch_size = 32  #@param\n",
        "eval_batch_size = 32  #@param\n",
        "initial_lr = 0.0  #@param\n",
        "peak_lr = 1e-4  #@param\n",
        "warmup_steps = 1000  #@param\n",
        "end_lr = 1e-6  #@param\n",
        "ema_decay = 0.999  #@param\n",
        "ckpt_interval = 1000  #@param\n",
        "max_ckpt_to_keep = 5  #@param"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr-be7CiFRhp"
      },
      "source": [
        "To start training, we first need to initialize the trainer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7E4WZUFEpzv"
      },
      "outputs": [],
      "source": [
        "# NOTE: use `trainers.DistributedDenoisingTrainer` for multi-device\n",
        "# training with data parallelism.\n",
        "trainer = dfn.DenoisingTrainer(\n",
        "    model=model,\n",
        "    rng=jax.random.PRNGKey(888),\n",
        "    optimizer=optax.adam(\n",
        "        learning_rate=optax.warmup_cosine_decay_schedule(\n",
        "            init_value=initial_lr,\n",
        "            peak_value=peak_lr,\n",
        "            warmup_steps=warmup_steps,\n",
        "            decay_steps=num_train_steps,\n",
        "            end_value=end_lr,\n",
        "        ),\n",
        "    ),\n",
        "    # We keep track of an exponential moving average of the model parameters\n",
        "    # over training steps. This alleviates the \"color-shift\" problems known to\n",
        "    # exist in the diffusion models.\n",
        "    ema_decay=ema_decay,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTQf9w1NFgp7"
      },
      "source": [
        "Now we are ready to kick start training. A couple of \"callbacks\" are passed to assist with monitoring and checkpointing.\n",
        "\n",
        "The first step will be a little slow as Jax needs to JIT compile the step function (the same goes for the first step where evaluation is performed). Fortunately, steps after that should continue much faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMQbydfdEpxQ"
      },
      "outputs": [],
      "source": [
        "templates.run_train(\n",
        "    train_dataloader=get_mnist_dataset(\n",
        "        split=\"train[:75%]\", batch_size=train_batch_size\n",
        "    ),\n",
        "    trainer=trainer,\n",
        "    workdir=workdir,\n",
        "    total_train_steps=num_train_steps,\n",
        "    metric_writer=metric_writers.create_default_writer(\n",
        "        workdir, asynchronous=False\n",
        "    ),\n",
        "    metric_aggregation_steps=100,\n",
        "    eval_dataloader=get_mnist_dataset(\n",
        "        split=\"train[75%:]\", batch_size=eval_batch_size\n",
        "    ),\n",
        "    eval_every_steps = 1000,\n",
        "    num_batches_per_eval = 2,\n",
        "    callbacks=(\n",
        "        # This callback displays the training progress in a tqdm bar\n",
        "        templates.TqdmProgressBar(\n",
        "            total_train_steps=num_train_steps,\n",
        "            train_monitors=(\"train_loss\",),\n",
        "        ),\n",
        "        # This callback saves model checkpoint periodically\n",
        "        templates.TrainStateCheckpoint(\n",
        "            base_dir=workdir,\n",
        "            options=ocp.CheckpointManagerOptions(\n",
        "                save_interval_steps=ckpt_interval, max_to_keep=max_ckpt_to_keep\n",
        "            ),\n",
        "        ),\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJDsoPMcFnJ0"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGPHjX8bFqrX"
      },
      "source": [
        "#### Unconditional generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUHa793NF0AS"
      },
      "source": [
        "After training is complete, the trained denoiser may be used to generate unconditional samples.\n",
        "\n",
        "First, let's restore the model from checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-CbKOV9EpvI"
      },
      "outputs": [],
      "source": [
        "# Restore train state from checkpoint. By default, the move recently saved\n",
        "# checkpoint is restored. Alternatively, one can directly use\n",
        "# `trainer.train_state` if continuing from the training section above.\n",
        "trained_state = dfn.DenoisingModelTrainState.restore_from_orbax_ckpt(\n",
        "    f\"{workdir}/checkpoints\", step=None\n",
        ")\n",
        "# Construct the inference function\n",
        "denoise_fn = dfn.DenoisingTrainer.inference_fn_from_state_dict(\n",
        "    trained_state, use_ema=True, denoiser=denoiser_model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nT2c5b6FF9jP"
      },
      "source": [
        "Diffusion samples are generated by plugging the trained denoising function in a stochastic differential equation (parametrized by the diffusion scheme) and solving it backwards in time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiOByVtjEpUs"
      },
      "outputs": [],
      "source": [
        "sampler = dfn_lib.SdeSampler(\n",
        "    input_shape=(28, 28, 1),\n",
        "    integrator=solver_lib.EulerMaruyama(),\n",
        "    tspan=dfn_lib.edm_noise_decay(\n",
        "        diffusion_scheme, rho=7, num_steps=256, end_sigma=1e-3,\n",
        "    ),\n",
        "    scheme=diffusion_scheme,\n",
        "    denoise_fn=denoise_fn,\n",
        "    guidance_transforms=(),\n",
        "    apply_denoise_at_end=True,\n",
        "    return_full_paths=False,  # Set to `True` if the full sampling paths are needed\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA26cPp0GBwC"
      },
      "source": [
        "The sampler may be run by calling its `.generate()` function. Optionally, we may JIT compile this function so that it runs faster if repeatedly called."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7yaiI7NF_61"
      },
      "outputs": [],
      "source": [
        "generate = jax.jit(sampler.generate, static_argnames=('num_samples',))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qUxgUaKGENj"
      },
      "outputs": [],
      "source": [
        "samples = generate(\n",
        "    rng=jax.random.PRNGKey(8888), num_samples=4\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTjpNNHtGH9c"
      },
      "source": [
        "Visualize the generated samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thhRfIe5GELQ"
      },
      "outputs": [],
      "source": [
        "# Plot generated samples\n",
        "fig, ax = plt.subplots(1, 4, figsize=(8, 2))\n",
        "for i in range(4):\n",
        "  im = ax[i].imshow(samples[i, :, :, 0] * 255, cmap=\"gray\", vmin=0, vmax=255)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Cr6J3hfGLi7"
      },
      "source": [
        "#### Guided generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8-3Hr5IGReH"
      },
      "source": [
        "To achieve 'guided' generation, we can modify a trained denoising function and tailor it to produce samples with specific desired characteristics. For instance, in an out-filling task where the goal is to generate full images from a given patch, we can guide the denoiser to create samples whose crops at certain positions precisely align with the provided patch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7P4li0qGEI4"
      },
      "outputs": [],
      "source": [
        "guidance_fn = dfn_lib.InfillFromSlices(\n",
        "    # This specifies location of the guide input using python slices.\n",
        "    # Here it implies that the guide input corresponds the 7x7 patch in the\n",
        "    # center of the image.\n",
        "    slices=(slice(None), slice(11, 18), slice(11, 18)),\n",
        "\n",
        "    # This is a parameter that controls how \"hard\" the denoiser pushes for\n",
        "    # the conditioning to be satisfied. It is a tradeoff between strictness of\n",
        "    # constraint satisfication and diversity in the generated samples.\n",
        "    guide_strength=0.1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D5zBynzGUdY"
      },
      "source": [
        "This transform function is passed through the `guidance_transforms` arg of the sampler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_kJnXqjGEGz"
      },
      "outputs": [],
      "source": [
        "guided_sampler = dfn_lib.SdeSampler(\n",
        "    input_shape=(28, 28, 1),\n",
        "    integrator=solver_lib.EulerMaruyama(),\n",
        "    tspan=dfn_lib.edm_noise_decay(\n",
        "        diffusion_scheme, rho=7, num_steps=256, end_sigma=1e-3,\n",
        "    ),\n",
        "    scheme=diffusion_scheme,\n",
        "    denoise_fn=denoise_fn,\n",
        "    guidance_transforms=(guidance_fn,),\n",
        "    apply_denoise_at_end=True,\n",
        "    return_full_paths=False,\n",
        ")\n",
        "\n",
        "guided_generate = jax.jit(guided_sampler.generate, static_argnames=('num_samples',))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcDPFQ9PGX9-"
      },
      "source": [
        "We construct an example guidance input from a real sample and use it to guide the sampling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5Uap93nGEEx"
      },
      "outputs": [],
      "source": [
        "test_ds = get_mnist_dataset(split=\"test\", batch_size=1)\n",
        "test_example = next(iter(test_ds))[\"x\"]\n",
        "example_guidance_inputs = {'observed_slices': test_example[:, 11:18, 11:18]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdUrseQOGECo"
      },
      "outputs": [],
      "source": [
        "guided_samples = guided_generate(\n",
        "    rng=jax.random.PRNGKey(66),\n",
        "    num_samples=4,\n",
        "    # Note that the shape of the guidance input must be compatible with\n",
        "    # `sample[guidance_fn.slices]`\n",
        "    guidance_inputs=example_guidance_inputs,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auf-UA3yGew-"
      },
      "source": [
        "Visualize guided samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72jBzmTCGEAg"
      },
      "outputs": [],
      "source": [
        "# Plot guide patch.\n",
        "fig, ax = plt.subplots(1, 1, figsize=(2, 2))\n",
        "im = ax.imshow(\n",
        "    test_example[0, 11:18, 11:18, 0] * 255, cmap=\"gray\", vmin=0, vmax=255\n",
        ")\n",
        "ax.axis(\"off\")\n",
        "ax.set_title(\"Guide patch\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot generated samples.\n",
        "fig, ax = plt.subplots(1, 4, figsize=(8, 2))\n",
        "for i in range(4):\n",
        "  im = ax[i].imshow(\n",
        "      guided_samples[i, :, :, 0] * 255, cmap=\"gray\", vmin=0, vmax=255\n",
        "  )\n",
        "  # Mark out the patch where guidance is enabled.\n",
        "  square = patches.Rectangle(\n",
        "      xy=(11, 11), width=7, height=7, fill=False, edgecolor='red'\n",
        "  )\n",
        "  ax[i].add_patch(square)\n",
        "  ax[i].axis(\"off\")\n",
        "  ax[i].set_title(f\"Sample #{i}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq4xz1w9GkFE"
      },
      "source": [
        "## Example II - Conditional diffusion model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElgwVoIPGxRq"
      },
      "source": [
        "In the above example, we trained an *unconditional* diffusion model and applied conditioning at inference time. This is not always easy to do, depending on how the conditioning input relates to the samples.\n",
        "\n",
        "Alternatively, we can directly *train a conditional model*, where the conditional signal is provided at training time as an additional input to the denoising neural network, which may then use it to compute the denoised target.\n",
        "\n",
        "Below we show an example of how to accomplish this. We again generate samples of handwritten digits, using the MNIST dataset for training. We will condition the generation on the `x[11:18, 11:18]` patch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U-O2msbGzEx"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba3Wn2YvG1oC"
      },
      "source": [
        "Besides the sample in `x`, the dataset for training conditional models require a `cond` key which contains the condition signals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IpRYEJtGD-Q"
      },
      "outputs": [],
      "source": [
        "def preproc_example(example: dict[str, tf.Tensor]):\n",
        "  processed = {}\n",
        "  processed[\"x\"] = tf.cast(example[\"image\"], tf.float32) / 255.0\n",
        "\n",
        "  # The \"channel:\" prefix indicate that the conditioning signal is to be\n",
        "  # incorporated by resizing and concatenating along the channel dimension.\n",
        "  # This is implemented at the backbone level.\n",
        "  processed[\"cond\"] = {\"channel:low_res\": processed[\"x\"][11:18, 11:18]}\n",
        "  return processed\n",
        "\n",
        "\n",
        "def get_cond_mnist_dataset(split: str, batch_size: int):\n",
        "  ds = tfds.load(\"mnist\", split=split)\n",
        "  ds = ds.map(preproc_example)\n",
        "  ds = ds.repeat()\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "  ds = ds.as_numpy_iterator()\n",
        "  return ds\n",
        "\n",
        "DATA_STD = 0.31"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yOBMiJtG7r3"
      },
      "source": [
        "### Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZNUY5kQG9xd"
      },
      "source": [
        "The architecture is similar to the unconditional case. We provide additional args that specify how to resize the conditioning signal (in order to be compatible with the noisy sample for channel-wise concatenation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5F8kNMAGiTR"
      },
      "outputs": [],
      "source": [
        "cond_denoiser_model = dfn_lib.PreconditionedDenoiserUNet(\n",
        "    out_channels=1,\n",
        "    num_channels=(64, 128),\n",
        "    downsample_ratio=(2, 2),\n",
        "    num_blocks=4,\n",
        "    noise_embed_dim=128,\n",
        "    padding=\"SAME\",\n",
        "    use_attention=True,\n",
        "    use_position_encoding=True,\n",
        "    num_heads=8,\n",
        "    sigma_data=DATA_STD,\n",
        "    cond_resize_method=\"cubic\",\n",
        "    cond_embed_dim=128,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19oJrFsjHCIZ"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT0JP9yAHEem"
      },
      "source": [
        "The `DenoisingModel` is again similar to the unconditional case. We additionally provide the shape information of the `cond` input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJFKb060GiRH"
      },
      "outputs": [],
      "source": [
        "diffusion_scheme = dfn_lib.Diffusion.create_variance_exploding(\n",
        "    sigma=dfn_lib.tangent_noise_schedule(),\n",
        "    data_std=DATA_STD,\n",
        ")\n",
        "\n",
        "cond_model = dfn.DenoisingModel(\n",
        "    input_shape=(28, 28, 1),\n",
        "    # `cond_shape` must agree with the expected structure and shape\n",
        "    # (without the batch dimension) of the `cond` input.\n",
        "    cond_shape={\"channel:low_res\": (7, 7, 1)},\n",
        "    denoiser=cond_denoiser_model,\n",
        "    noise_sampling=dfn_lib.log_uniform_sampling(\n",
        "        diffusion_scheme, clip_min=1e-4, uniform_grid=True,\n",
        "    ),\n",
        "    noise_weighting=dfn_lib.edm_weighting(data_std=DATA_STD),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81Bktr9gHHjz"
      },
      "source": [
        "The rest mostly repeats the unconditional training example, replacing the datasets and model with their conditional counterparts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyEsCCSbGiPC"
      },
      "outputs": [],
      "source": [
        "# !rm -R -f $cond_workdir  # optional: clear the working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekXD8PprGiM8"
      },
      "outputs": [],
      "source": [
        "num_train_steps = 100_000  #@param\n",
        "cond_workdir = \"/tmp/cond_diffusion_demo_mnist\"  #@param\n",
        "train_batch_size = 32  #@param\n",
        "eval_batch_size = 32  #@param\n",
        "initial_lr = 0.0  #@param\n",
        "peak_lr = 1e-4  #@param\n",
        "warmup_steps = 1000  #@param\n",
        "end_lr = 1e-6  #@param\n",
        "ema_decay = 0.999  #@param\n",
        "ckpt_interval = 1000  #@param\n",
        "max_ckpt_to_keep = 5  #@param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DDpmV-zGiKW"
      },
      "outputs": [],
      "source": [
        "cond_trainer = dfn.DenoisingTrainer(\n",
        "    model=cond_model,\n",
        "    rng=jax.random.PRNGKey(888),\n",
        "    optimizer=optax.adam(\n",
        "        learning_rate=optax.warmup_cosine_decay_schedule(\n",
        "            init_value=initial_lr,\n",
        "            peak_value=peak_lr,\n",
        "            warmup_steps=warmup_steps,\n",
        "            decay_steps=num_train_steps,\n",
        "            end_value=end_lr,\n",
        "        ),\n",
        "    ),\n",
        "    ema_decay=ema_decay,\n",
        ")\n",
        "\n",
        "templates.run_train(\n",
        "    train_dataloader=get_cond_mnist_dataset(\n",
        "        split=\"train[:75%]\", batch_size=train_batch_size\n",
        "    ),\n",
        "    trainer=cond_trainer,\n",
        "    workdir=cond_workdir,\n",
        "    total_train_steps=num_train_steps,\n",
        "    metric_writer=metric_writers.create_default_writer(\n",
        "        cond_workdir, asynchronous=False\n",
        "    ),\n",
        "    metric_aggregation_steps=100,\n",
        "    eval_dataloader=get_cond_mnist_dataset(\n",
        "        split=\"train[75%:]\", batch_size=eval_batch_size\n",
        "    ),\n",
        "    eval_every_steps = 1000,\n",
        "    num_batches_per_eval = 2,\n",
        "    callbacks=(\n",
        "        templates.TqdmProgressBar(\n",
        "            total_train_steps=num_train_steps,\n",
        "            train_monitors=(\"train_loss\",),\n",
        "        ),\n",
        "        templates.TrainStateCheckpoint(\n",
        "            base_dir=cond_workdir,\n",
        "            options=ocp.CheckpointManagerOptions(\n",
        "                save_interval_steps=ckpt_interval, max_to_keep=max_ckpt_to_keep\n",
        "            ),\n",
        "        ),\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojUo2JDEHPCN"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS0m_f0CHR5i"
      },
      "source": [
        "To perform inference/sampling, let's load back the trained conditional model checkpoint:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RHlke6pGiHx"
      },
      "outputs": [],
      "source": [
        "trained_state = dfn.DenoisingModelTrainState.restore_from_orbax_ckpt(\n",
        "    f\"{cond_workdir}/checkpoints\", step=None\n",
        ")\n",
        "# Construct the inference function\n",
        "cond_denoise_fn = dfn.DenoisingTrainer.inference_fn_from_state_dict(\n",
        "    trained_state, use_ema=True, denoiser=cond_denoiser_model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3crKP7hqHV7I"
      },
      "source": [
        "The conditional sampler again follows the previous example, with the only exception being that the conditional model replaces the unconditional one.\n",
        "\n",
        "Below we do not apply any guidance, but one can be easily added in the same way as in the unconditional example above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnaFzOjOHOu4"
      },
      "outputs": [],
      "source": [
        "cond_sampler = dfn_lib.SdeSampler(\n",
        "    input_shape=(28, 28, 1),\n",
        "    integrator=solver_lib.EulerMaruyama(),\n",
        "    tspan=dfn_lib.edm_noise_decay(\n",
        "        diffusion_scheme, rho=7, num_steps=256, end_sigma=1e-3,\n",
        "    ),\n",
        "    scheme=diffusion_scheme,\n",
        "    denoise_fn=cond_denoise_fn,\n",
        "    guidance_transforms=(),\n",
        "    apply_denoise_at_end=True,\n",
        "    return_full_paths=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lYF1OUEHZFM"
      },
      "source": [
        "We again JIT the generate function for the sake of faster repeated sampling calls. Here we employ `functools.partial` to specify `num_samples=5`, making it easier to vectorize across the batch dimension with `jax.vmap`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mT_rLzdgHOsm"
      },
      "outputs": [],
      "source": [
        "num_samples_per_cond = 5\n",
        "\n",
        "generate = jax.jit(\n",
        "    functools.partial(cond_sampler.generate, num_samples_per_cond)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_9TfCMSHd3P"
      },
      "source": [
        "Loading a test batch of conditions with 4 elements:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tODWrPBfHOqN"
      },
      "outputs": [],
      "source": [
        "batch_size = 4\n",
        "test_ds = get_cond_mnist_dataset(split=\"test\", batch_size=4)\n",
        "test_batch_cond = next(iter(test_ds))[\"cond\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HJXzAtzHhli"
      },
      "source": [
        "The vectorized generate function is applied to the loaded batch. The vectorization occurs for the leading dimensions of both the random seed and the condition (for those unfamiliarized with vectorized operations in jax, think of a more efficient `for` loop that iterates over the random seeds and batch conditions zipped together)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29oPpGuWHhYP"
      },
      "outputs": [],
      "source": [
        "cond_samples = jax.vmap(generate, in_axes=(0, 0, None))(\n",
        "    jax.random.split(jax.random.PRNGKey(8888), batch_size),\n",
        "    test_batch_cond,\n",
        "    None,  # Guidance inputs = None since no guidance transforms involved\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH9CozY8Hkgv"
      },
      "source": [
        "The result `cond_samples` has shape `(batch_size, num_samples_per_cond, *input_shape)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSQHV5FmHOoK"
      },
      "outputs": [],
      "source": [
        "print(cond_samples.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Br6clK2cHow9"
      },
      "source": [
        "Visualize generated examples alongside their low-res conditioning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7c5wXDcHOkP"
      },
      "outputs": [],
      "source": [
        "for i in range(batch_size):\n",
        "  fig, ax = plt.subplots(1, 1, figsize=(2, 2))\n",
        "  im = ax.imshow(\n",
        "      test_batch_cond[\"channel:low_res\"][i, :, :, 0] * 255,\n",
        "      cmap=\"gray\", vmin=0, vmax=255\n",
        "  )\n",
        "  ax.axis(\"off\")\n",
        "  ax.set_title(f\"Low-res condition: #{i + 1}\")\n",
        "\n",
        "\n",
        "  # Plot generated samples.\n",
        "  fig, ax = plt.subplots(\n",
        "      1, num_samples_per_cond, figsize=(num_samples_per_cond * 2, 2)\n",
        "  )\n",
        "  for j in range(num_samples_per_cond):\n",
        "    im = ax[j].imshow(\n",
        "        cond_samples[i, j, :, :, 0] * 255, cmap=\"gray\", vmin=0, vmax=255\n",
        "    )\n",
        "    square = patches.Rectangle(\n",
        "        xy=(11, 11), width=7, height=7, fill=False, edgecolor='red'\n",
        "    )\n",
        "    ax[j].add_patch(square)\n",
        "    ax[j].set_title(f\"conditional sample: #{j + 1}\")\n",
        "    ax[j].axis(\"off\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from scipy.integrate import solve_ivp\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 步骤1：生成带时滞的系统数据（模拟观测数据）\n",
        "# ------------------------------------------------------\n",
        "def delayed_logistic(t, x, r, K, tau, history):\n",
        "    \"\"\"时滞Logistic方程的导数计算（需历史数据）\"\"\"\n",
        "    # 从历史数据中插值得到x(t-tau)\n",
        "    t_prev = t - tau\n",
        "    if t_prev < history[0,0]:  # 若t-tau早于历史数据起点，用初始值\n",
        "        x_prev = history[0,1]\n",
        "    else:\n",
        "        x_prev = np.interp(t_prev, history[:,0], history[:,1])  # 线性插值\n",
        "    dxdt = r * x * (1 - x_prev / K)\n",
        "    return dxdt\n",
        "\n",
        "# 系统参数（已知真实时滞tau=0.5）\n",
        "r = 0.5\n",
        "K = 10.0\n",
        "tau_true = 0.5  # 真实时滞\n",
        "t_start = 0.0\n",
        "t_end = 50.0\n",
        "dt = 0.01  # 采样步长\n",
        "t = np.arange(t_start, t_end, dt)\n",
        "x0 = 2.0  # 初始值\n",
        "\n",
        "# 生成历史数据（用于计算时滞项）\n",
        "history_t = np.arange(t_start - 2*tau_true, t_start, dt)  # 历史时间（覆盖2倍时滞）\n",
        "history_x = np.ones_like(history_t) * x0  # 历史状态（假设初始平稳）\n",
        "history = np.column_stack((history_t, history_x))\n",
        "\n",
        "# 数值求解时滞微分方程（生成观测数据）\n",
        "sol = solve_ivp(\n",
        "    fun=delayed_logistic,\n",
        "    t_span=(t_start, t_end),\n",
        "    y0=[x0],\n",
        "    args=(r, K, tau_true, history),\n",
        "    t_eval=t,\n",
        "    method='RK45'\n",
        ")\n",
        "x = sol.y[0]  # 系统状态x(t)\n",
        "dxdt = np.gradient(x, dt)  # 数值求导得到dx/dt（模拟观测导数）\n",
        "\n",
        "# 加入噪声（模拟实际测量噪声）\n",
        "np.random.seed(42)\n",
        "noise_level = 0.05  # 噪声强度\n",
        "x_noisy = x + noise_level * np.random.randn(len(x))\n",
        "dxdt_noisy = dxdt + noise_level * np.random.randn(len(dxdt))\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 步骤2：构建候选时滞池（基于先验知识缩小范围）\n",
        "# ------------------------------------------------------\n",
        "# 假设通过物理分析已知时滞可能在0~1s之间，离散选取候选值\n",
        "tau_candidates = np.array([0.1, 0.3, 0.5, 0.7, 1.0])  # 候选时滞池\n",
        "n_tau = len(tau_candidates)\n",
        "\n",
        "# 将时滞转换为时间步索引（方便从离散数据中取时滞项）\n",
        "tau_steps = np.round(tau_candidates / dt).astype(int)  # 时滞对应的采样步数\n",
        "print(f\"候选时滞（秒）：{tau_candidates}\")\n",
        "print(f\"对应采样步数：{tau_steps}\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 步骤3：构造特征库（含时滞项及非线性组合）\n",
        "# ------------------------------------------------------\n",
        "# 提取各候选时滞对应的x(t-tau)\n",
        "n_samples = len(x_noisy)\n",
        "features = []\n",
        "for step in tau_steps:\n",
        "    # 对时滞项做位移（确保t-tau不越界）\n",
        "    if step == 0:\n",
        "        x_tau = x_noisy  # 无时滞\n",
        "    else:\n",
        "        x_tau = np.roll(x_noisy, shift=step)  # 滚动取时滞项\n",
        "        x_tau[:step] = x_noisy[0]  # 前step个值用初始值填充（避免越界）\n",
        "    features.append(x_tau)\n",
        "\n",
        "# 将特征转换为矩阵（每行是一个样本，每列是一个特征）\n",
        "features = np.column_stack(features)  # 形状：(n_samples, n_tau)\n",
        "\n",
        "# 加入非线性特征（二次项、交叉项，模拟SINDy的非线性特征库）\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)  # 二次多项式特征\n",
        "features_poly = poly.fit_transform(features)  # 形状：(n_samples, n_features)\n",
        "print(f\"特征库维度（含非线性项）：{features_poly.shape}\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 步骤4：稀疏回归筛选有效时滞（LASSO）\n",
        "# ------------------------------------------------------\n",
        "# 训练LASSO模型（正则化参数alpha控制稀疏性）\n",
        "lasso = Lasso(alpha=0.01, max_iter=10000)\n",
        "lasso.fit(features_poly, dxdt_noisy)\n",
        "\n",
        "# 提取非零系数对应的特征\n",
        "coef = lasso.coef_\n",
        "nonzero_idx = np.where(np.abs(coef) > 1e-5)[0]  # 筛选显著非零系数\n",
        "print(f\"非零系数索引：{nonzero_idx}\")\n",
        "\n",
        "# 解析非零特征对应的时滞（通过多项式特征的元数据反向映射）\n",
        "feature_names = poly.get_feature_names_out([f'tau={tau}' for tau in tau_candidates])\n",
        "print(\"\\n识别出的有效特征（时滞项及非线性组合）：\")\n",
        "for idx in nonzero_idx:\n",
        "    print(f\"特征：{feature_names[idx]}, 系数：{coef[idx]:.4f}\")\n",
        "\n",
        "# 提取核心时滞（从有效特征中解析出真实时滞）\n",
        "identified_taus = set()\n",
        "for idx in nonzero_idx:\n",
        "    # 从特征名中提取时滞值（如'tau=0.5' -> 0.5）\n",
        "    for tau in tau_candidates:\n",
        "        if f'tau={tau}' in feature_names[idx]:\n",
        "            identified_taus.add(tau)\n",
        "identified_taus = np.array(list(identified_taus))\n",
        "print(f\"\\n识别出的时滞（秒）：{identified_taus}\")\n",
        "print(f\"真实时滞（秒）：{tau_true}\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# 步骤5：验证结果（可视化模型预测效果）\n",
        "# ------------------------------------------------------\n",
        "# 用识别出的模型预测dx/dt\n",
        "dxdt_pred = lasso.predict(features_poly)\n",
        "\n",
        "# 绘图对比\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(t, x_noisy, label='x(t)（with nosie）')\n",
        "plt.xlabel('t (s)')\n",
        "plt.ylabel('x(t)')\n",
        "plt.title('state')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(t, dxdt_noisy, label='real dx/dt（with nosie）', alpha=0.5)\n",
        "plt.plot(t, dxdt_pred, label='SINDy pred dx/dt', color='r', linestyle='--')\n",
        "plt.xlabel('t (s)')\n",
        "plt.ylabel('dx/dt')\n",
        "plt.title(f'delay test：real={tau_true}s, indentify={identified_taus}s')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KTX08JVW6uK2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "A100",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}